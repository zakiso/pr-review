#!/usr/bin/env python3
"""
LLM-based PR Validator
----------------------
Uses OpenAI's API to evaluate PR quality and provide improvement suggestions.
"""

import os
import sys
import json
import time
import requests
from openai import OpenAI

def post_comment(comment):
    """Post a comment to the PR"""
    token = os.environ.get('GITHUB_TOKEN')
    pr_number = os.environ.get('PR_NUMBER')
    repo = os.environ.get('REPO_FULL_NAME')
    
    if not all([token, pr_number, repo]):
        return
    
    url = f"https://api.github.com/repos/{repo}/issues/{pr_number}/comments"
    headers = {
        "Accept": "application/vnd.github.v3+json",
        "Authorization": f"token {token}",
        "Content-Type": "application/json"
    }
    data = {"body": comment}
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(data))
        response.raise_for_status()
    except Exception as e:
        print(f"Warning: Failed to post comment to PR: {e}")

def evaluate_pr_with_llm(title, body):
    """Evaluate PR quality using OpenAI API"""
    # Get API key and model from env vars
    api_key = os.environ.get('OPENAI_API_KEY')
    model_name = os.environ.get('MODEL_NAME', 'gpt-4')

    if not api_key:
        print("‚ùå Error: OPENAI_API_KEY environment variable is not set")
        sys.exit(1)
    
    # Initialize OpenAI client
    client = OpenAI(api_key=api_key)
    
    # Create the prompt for the LLM
    prompt = f"""
You are an expert code reviewer tasked with evaluating the quality of a GitHub Pull Request.
Analyze the following PR title and description to determine if it meets high-quality standards.

PR Title: {title}
PR Description:
{body}

Evaluate based on these criteria:
1. Clarity: Is the purpose of the PR clearly communicated?
2. Completeness: Does it explain what changes were made and why?
3. Technical Detail: Are implementation details sufficiently explained?
4. Testing: Is there information about how the changes were tested?

Respond with a JSON object containing:
{{
  "quality_score": [1-10 integer score],
  "is_acceptable": [boolean, true if score >= 6],
  "strengths": [array of strengths],
  "improvement_suggestions": [array of specific suggestions for improvement],
  "explanation": [brief explanation of your evaluation]
}}
"""

    # Maximum retries for API call
    max_retries = 3
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            print(f"ü§ñ Evaluating PR with {model_name}...")
            response = client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            # Extract the response content
            content = response.choices[0].message.content
            
            try:
                result = json.loads(content)
                return result
            except json.JSONDecodeError:
                print(f"Error parsing JSON from API response: {content[:200]}...")
                retry_count += 1
                time.sleep(2)
                
        except Exception as e:
            print(f"Error calling OpenAI API: {e}")
            retry_count += 1
            time.sleep(2)
    
    print("‚ùå Failed to get a valid response from the OpenAI API after multiple retries")
    sys.exit(1)

def format_feedback_comment(result):
    """Format the LLM feedback as a GitHub comment"""
    emoji_map = {
        1: "üö®", 2: "üö®", 3: "üö®", 4: "‚ö†Ô∏è", 5: "‚ö†Ô∏è",
        6: "üëç", 7: "üëç", 8: "‚úÖ", 9: "üåü", 10: "üåü"
    }
    
    score = result["quality_score"]
    emoji = emoji_map.get(score, "üîç")
    
    comment = f"""
## {emoji} PR Quality Assessment

**Score: {score}/10** - {result["explanation"]}

### Strengths
{chr(10).join([f"- {s}" for s in result["strengths"]])}

### Suggestions for Improvement
{chr(10).join([f"- {s}" for s in result["improvement_suggestions"]])}

---
*This assessment was generated by an AI. Please consider these suggestions as helpful guidance.*
"""
    return comment

def main():
    """Main function to validate PR using LLM"""
    if len(sys.argv) < 2:
        print("Usage: python llm_check.py <PR title> [PR body]")
        sys.exit(1)
    
    pr_title = sys.argv[1]
    pr_body = sys.argv[2] if len(sys.argv) > 2 else ""
    
    # Run LLM evaluation
    evaluation = evaluate_pr_with_llm(pr_title, pr_body)
    
    # Print results
    print(f"ü§ñ LLM Quality Score: {evaluation['quality_score']}/10")
    print(f"ü§ñ Acceptable: {'Yes' if evaluation['is_acceptable'] else 'No'}")
    print("\nü§ñ Strengths:")
    for strength in evaluation['strengths']:
        print(f"  - {strength}")
    
    print("\nü§ñ Improvement Suggestions:")
    for suggestion in evaluation['improvement_suggestions']:
        print(f"  - {suggestion}")
    
    print(f"\nü§ñ Explanation: {evaluation['explanation']}")
    
    # Post comment to GitHub if possible
    formatted_comment = format_feedback_comment(evaluation)
    post_comment(formatted_comment)
    
    # Exit with appropriate status code
    if not evaluation['is_acceptable']:
        print("\n‚ùå PR quality does not meet minimum standards. See suggestions above.")
        sys.exit(1)
    else:
        print("\n‚úÖ PR quality meets minimum standards.")
        sys.exit(0)

if __name__ == "__main__":
    main()