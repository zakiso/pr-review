#!/usr/bin/env python3
"""
LLM-based PR Validator
----------------------
Uses OpenAI's API to evaluate PR quality and provide improvement suggestions.
"""

import os
import sys
import json
import time
import requests
from openai import OpenAI

def post_comment(comment):
    """Post a comment to the PR"""
    token = os.environ.get('GITHUB_TOKEN')
    pr_number = os.environ.get('PR_NUMBER')
    repo = os.environ.get('REPO_FULL_NAME')
    
    if not all([token, pr_number, repo]):
        print("ERROR: ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡ (GITHUB_TOKEN, PR_NUMBER æˆ– REPO_FULL_NAME)")
        return
    
    print(f"DEBUG: å‘é€è¯„è®ºåˆ° PR #{pr_number} åœ¨ä»“åº“ {repo}")
    print(f"DEBUG: ä½¿ç”¨çš„ä»¤ç‰Œ (å‰4ä½): {token[:4]}...")
    
    # è¾“å‡ºè¯„è®ºå†…å®¹ (ç”¨äºæµ‹è¯•)
    print("INFO: å°†å‘é€ä»¥ä¸‹è¯„è®ºåˆ° PR (å¦‚æœæœ‰æƒé™):")
    print("---BEGIN COMMENT---")
    print(comment[:200] + "..." if len(comment) > 200 else comment)
    print("---END COMMENT---")
    
    url = f"https://api.github.com/repos/{repo}/issues/{pr_number}/comments"
    headers = {
        "Accept": "application/vnd.github.v3+json",
        "Authorization": f"token {token}",
        "Content-Type": "application/json"
    }
    data = {"body": comment}
    
    try:
        response = requests.post(url, headers=headers, json=data)
        print(f"DEBUG: å“åº”çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 201:
            print("INFO: è¯„è®ºæˆåŠŸå‘é€")
            return True
            
        response.raise_for_status()
    except Exception as e:
        print(f"ERROR: å‘é€è¯„è®ºå¤±è´¥: {e}")
        if hasattr(e, 'response') and e.response:
            print(f"å“åº”çŠ¶æ€: {e.response.status_code}")
            print(f"å“åº”å†…å®¹: {e.response.text}")
    
    return False

def evaluate_pr_with_llm(title, body):
    """Evaluate PR quality using OpenAI API"""
    # Get API key and model from env vars
    api_key = os.environ.get('OPENAI_API_KEY')
    model_name = os.environ.get('MODEL_NAME', 'gpt-4')

    if not api_key:
        print("âŒ Error: OPENAI_API_KEY environment variable is not set")
        sys.exit(1)
    
    # Initialize OpenAI client
    client = OpenAI(api_key=api_key)
    
    # Create the prompt for the LLM
    prompt = f"""
You are an expert code reviewer tasked with evaluating the quality of a GitHub Pull Request.
Analyze the following PR title and description to determine if it meets high-quality standards.

PR Title: {title}
PR Description:
{body}

Evaluate based on these criteria:
1. Clarity: Is the purpose of the PR clearly communicated?
2. Completeness: Does it explain what changes were made and why?
3. Technical Detail: Are implementation details sufficiently explained?
4. Testing: Is there information about how the changes were tested?

Respond with a JSON object containing:
{{
  "quality_score": [1-10 integer score],
  "is_acceptable": [boolean, true if score >= 6],
  "strengths": [array of strengths],
  "improvement_suggestions": [array of specific suggestions for improvement],
  "explanation": [brief explanation of your evaluation]
}}
"""

    # Maximum retries for API call
    max_retries = 3
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            print(f"ğŸ¤– ä½¿ç”¨ {model_name} è¯„ä¼° PR...")
            response = client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            # Extract the response content
            content = response.choices[0].message.content
            
            try:
                result = json.loads(content)
                return result
            except json.JSONDecodeError:
                print(f"Error parsing JSON from API response: {content[:200]}...")
                retry_count += 1
                time.sleep(2)
                
        except Exception as e:
            print(f"Error calling OpenAI API: {e}")
            retry_count += 1
            time.sleep(2)
    
    print("âŒ Failed to get a valid response from the OpenAI API after multiple retries")
    sys.exit(1)

def format_feedback_comment(result):
    """Format the LLM feedback as a GitHub comment"""
    emoji_map = {
        1: "ğŸš¨", 2: "ğŸš¨", 3: "ğŸš¨", 4: "âš ï¸", 5: "âš ï¸",
        6: "ğŸ‘", 7: "ğŸ‘", 8: "âœ…", 9: "ğŸŒŸ", 10: "ğŸŒŸ"
    }
    
    score = result["quality_score"]
    emoji = emoji_map.get(score, "ğŸ”")
    
    comment = f"""
## {emoji} PR è´¨é‡è¯„ä¼°

**è¯„åˆ†: {score}/10** - {result["explanation"]}

### ä¼˜ç‚¹
{chr(10).join([f"- {s}" for s in result["strengths"]])}

### æ”¹è¿›å»ºè®®
{chr(10).join([f"- {s}" for s in result["improvement_suggestions"]])}

---
*æ­¤è¯„ä¼°ç”± AI ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒã€‚*
"""
    return comment

def main():
    """Main function to validate PR using LLM"""
    if len(sys.argv) < 2:
        print("Usage: python llm_check.py <PR title> [PR body]")
        sys.exit(1)
    
    pr_title = sys.argv[1]
    pr_body = sys.argv[2] if len(sys.argv) > 2 else ""
    
    print(f"DEBUG: è¯„ä¼° PR æ ‡é¢˜: '{pr_title}'")
    print(f"DEBUG: PR æè¿°é•¿åº¦: {len(pr_body)} å­—ç¬¦")
    
    # Run LLM evaluation
    evaluation = evaluate_pr_with_llm(pr_title, pr_body)
    
    # Print results
    print(f"ğŸ¤– LLM è´¨é‡è¯„åˆ†: {evaluation['quality_score']}/10")
    print(f"ğŸ¤– æ˜¯å¦å¯æ¥å—: {'æ˜¯' if evaluation['is_acceptable'] else 'å¦'}")
    print("\nğŸ¤– ä¼˜ç‚¹:")
    for strength in evaluation['strengths']:
        print(f"  - {strength}")
    
    print("\nğŸ¤– æ”¹è¿›å»ºè®®:")
    for suggestion in evaluation['improvement_suggestions']:
        print(f"  - {suggestion}")
    
    print(f"\nğŸ¤– è¯„ä»·: {evaluation['explanation']}")
    
    # Post comment to GitHub if possible
    formatted_comment = format_feedback_comment(evaluation)
    comment_success = post_comment(formatted_comment)
    
    if not comment_success:
        print("\nWARNING: æ— æ³•å‘é€è¯„è®ºåˆ° PRï¼Œä½†å°†ç»§ç»­å¤„ç†")
        print("è¯„è®ºå†…å®¹å¦‚ä¸‹:\n")
        print(formatted_comment)
    
    # Exit with appropriate status code
    if not evaluation['is_acceptable']:
        print("\nâŒ PR è´¨é‡ä¸ç¬¦åˆæœ€ä½æ ‡å‡†ã€‚è¯·å‚è€ƒä¸Šè¿°å»ºè®®ã€‚")
        sys.exit(1)
    else:
        print("\nâœ… PR è´¨é‡ç¬¦åˆæœ€ä½æ ‡å‡†ã€‚")
        sys.exit(0)

if __name__ == "__main__":
    main()