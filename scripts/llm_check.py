#!/usr/bin/env python3
"""
LLM-based PR Validator
----------------------
Uses OpenAI's API to evaluate PR quality and provide improvement suggestions.
"""

import os
import sys
import json
import time
import subprocess
from pathlib import Path
from openai import OpenAI

def call_report_check(title, summary, text, conclusion):
    """è°ƒç”¨ report_check.py ç”ŸæˆæŠ¥å‘Š"""
    script_dir = Path(__file__).parent
    report_script = script_dir / "report_check.py"
    
    # ç¡®ä¿æŠ¥å‘Šè„šæœ¬å­˜åœ¨
    if not report_script.exists():
        print(f"ERROR: æ‰¾ä¸åˆ°æŠ¥å‘Šè„šæœ¬: {report_script}")
        return False
    
    try:
        subprocess.run([
            "python", str(report_script),
            "--title", title,
            "--summary", summary,
            "--text", text,
            "--conclusion", conclusion
        ], check=True)
        return True
    except subprocess.CalledProcessError as e:
        print(f"ERROR: è°ƒç”¨æŠ¥å‘Šè„šæœ¬å¤±è´¥: {e}")
        return False

def evaluate_pr_with_llm(title, body):
    """Evaluate PR quality using OpenAI API"""
    # Get API key and model from env vars
    api_key = os.environ.get('OPENAI_API_KEY')
    model_name = os.environ.get('MODEL_NAME', 'gpt-4')

    if not api_key:
        print("âŒ Error: OPENAI_API_KEY environment variable is not set")
        # ç›´æ¥è°ƒç”¨ report_check.py æŠ¥å‘Šé”™è¯¯
        call_report_check(
            "LLM è¯„ä¼°å¤±è´¥", 
            "ç¼ºå°‘ OpenAI API å¯†é’¥ã€‚", 
            "è¯·é…ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡ã€‚", 
            "failure"
        )
        sys.exit(1)
    
    # Initialize OpenAI client
    client = OpenAI(api_key=api_key)
    
    # Create the prompt for the LLM
    prompt = f"""
You are an expert code reviewer tasked with evaluating the quality of a GitHub Pull Request.
Analyze the following PR title and description to determine if it meets high-quality standards.

PR Title: {title}
PR Description:
{body}

Evaluate based on these criteria:
1. Clarity: Is the purpose of the PR clearly communicated?
2. Completeness: Does it explain what changes were made and why?
3. Technical Detail: Are implementation details sufficiently explained?
4. Testing: Is there information about how the changes were tested?

Respond with a JSON object containing:
{{
  "quality_score": [1-10 integer score],
  "is_acceptable": [boolean, true if score >= 6],
  "strengths": [array of strengths],
  "improvement_suggestions": [array of specific suggestions for improvement],
  "explanation": [brief explanation of your evaluation]
}}
"""

    # Maximum retries for API call
    max_retries = 3
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            print(f"ğŸ¤– ä½¿ç”¨ {model_name} è¯„ä¼° PR...")
            response = client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            
            # Extract the response content
            content = response.choices[0].message.content
            
            try:
                result = json.loads(content)
                return result
            except json.JSONDecodeError:
                print(f"Error parsing JSON from API response: {content[:200]}...")
                retry_count += 1
                time.sleep(2)
                
        except Exception as e:
            print(f"Error calling OpenAI API: {e}")
            retry_count += 1
            time.sleep(2)
    
    print("âŒ Failed to get a valid response from the OpenAI API after multiple retries")
    # ç›´æ¥è°ƒç”¨ report_check.py æŠ¥å‘Šé”™è¯¯
    call_report_check(
        "LLM è¯„ä¼°å¤±è´¥", 
        "æ— æ³•è·å–æœ‰æ•ˆçš„ LLM å“åº”ã€‚", 
        "åœ¨å¤šæ¬¡é‡è¯•åä»æ— æ³•ä» OpenAI API è·å–æœ‰æ•ˆå“åº”ã€‚è¯·æ£€æŸ¥ API è¿æ¥å’Œæ¨¡å‹å¯ç”¨æ€§ã€‚", 
        "failure"
    )
    sys.exit(1)

def format_feedback_text(result):
    """Format the LLM feedback as a report text"""
    emoji_map = {
        1: "ğŸš¨", 2: "ğŸš¨", 3: "ğŸš¨", 4: "âš ï¸", 5: "âš ï¸",
        6: "ğŸ‘", 7: "ğŸ‘", 8: "âœ…", 9: "ğŸŒŸ", 10: "ğŸŒŸ"
    }
    
    score = result["quality_score"]
    emoji = emoji_map.get(score, "ğŸ”")
    
    report_text = f"""
## {emoji} PR è´¨é‡è¯„ä¼°

**è¯„åˆ†: {score}/10** - {result["explanation"]}

### ä¼˜ç‚¹
{chr(10).join([f"- {s}" for s in result["strengths"]])}

### æ”¹è¿›å»ºè®®
{chr(10).join([f"- {s}" for s in result["improvement_suggestions"]])}

---
*æ­¤è¯„ä¼°ç”± AI ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒã€‚*
"""
    return report_text

def main():
    """Main function to validate PR using LLM"""
    if len(sys.argv) < 2:
        print("Usage: python llm_check.py <PR title> [PR body]")
        sys.exit(1)
    
    pr_title = sys.argv[1]
    pr_body = sys.argv[2] if len(sys.argv) > 2 else ""
    
    print(f"DEBUG: è¯„ä¼° PR æ ‡é¢˜: '{pr_title}'")
    print(f"DEBUG: PR æè¿°é•¿åº¦: {len(pr_body)} å­—ç¬¦")
    
    # Run LLM evaluation
    evaluation = evaluate_pr_with_llm(pr_title, pr_body)
    
    # Print results
    print(f"ğŸ¤– LLM è´¨é‡è¯„åˆ†: {evaluation['quality_score']}/10")
    print(f"ğŸ¤– æ˜¯å¦å¯æ¥å—: {'æ˜¯' if evaluation['is_acceptable'] else 'å¦'}")
    print("\nğŸ¤– ä¼˜ç‚¹:")
    for strength in evaluation['strengths']:
        print(f"  - {strength}")
    
    print("\nğŸ¤– æ”¹è¿›å»ºè®®:")
    for suggestion in evaluation['improvement_suggestions']:
        print(f"  - {suggestion}")
    
    print(f"\nğŸ¤– è¯„ä»·: {evaluation['explanation']}")
    
    # Format the feedback
    report_text = format_feedback_text(evaluation)
    
    # å‡†å¤‡æ£€æŸ¥ç»“æœå‚æ•°
    if evaluation['is_acceptable']:
        title = "PR è´¨é‡è¯„ä¼°é€šè¿‡"
        summary = f"PR è´¨é‡è¯„åˆ†: {evaluation['quality_score']}/10ï¼Œè¾¾åˆ°åˆæ ¼æ ‡å‡†ã€‚"
        conclusion = "success"
    else:
        title = "PR è´¨é‡è¯„ä¼°æœªé€šè¿‡"
        summary = f"PR è´¨é‡è¯„åˆ†: {evaluation['quality_score']}/10ï¼Œæœªè¾¾åˆ°åˆæ ¼æ ‡å‡†ã€‚"
        conclusion = "failure"
    
    # ç›´æ¥è°ƒç”¨ report_check.py
    call_report_check(title, summary, report_text, conclusion)
    
    # Exit with appropriate status code
    if not evaluation['is_acceptable']:
        print("\nâŒ PR è´¨é‡ä¸ç¬¦åˆæœ€ä½æ ‡å‡†ã€‚è¯·å‚è€ƒä¸Šè¿°å»ºè®®ã€‚")
        sys.exit(1)
    else:
        print("\nâœ… PR è´¨é‡ç¬¦åˆæœ€ä½æ ‡å‡†ã€‚")
        sys.exit(0)

if __name__ == "__main__":
    main()